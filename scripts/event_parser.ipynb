{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "output_path = \"./../output/population/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading events to separate tables\n",
    "* agents: people\n",
    "* vehicles:\n",
    "    * cars\n",
    "    * subway\n",
    "    * buses\n",
    "    * trams\n",
    "    * trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.DataFrame()\n",
    "\n",
    "dtypes = {\n",
    "    \"Unnamed: 0\" : np.float64,\n",
    "    \"time\": np.float64,\n",
    "    \"type\": str,\n",
    "    \"driverId\": str,\n",
    "    \"vehicleId\": str,\n",
    "    \"transitLineId\": str,\n",
    "    \"transitRouteId\": str,\n",
    "    \"departureId\": str,\n",
    "    \"person\": str,\n",
    "    \"link\": str,\n",
    "    \"legMode\": 'category', #category\n",
    "    \"vehicle\": str,\n",
    "    \"networkMode\": str, #category\n",
    "    \"relativePosition\": np.float64,\n",
    "    \"facility\": str,\n",
    "    \"delay\": np.float64,\n",
    "    \"x\": np.float64,\n",
    "    \"y\": np.float64,\n",
    "    \"actType\": str,\n",
    "    \"computationalRoutingMode\": str,\n",
    "    \"distance\" : np.float64,\n",
    "    \"mode\": str,\n",
    "    \"agent\": str,\n",
    "    \"atStop\": str\n",
    "}\n",
    "\n",
    "#reading all events at once, will be an issue for 100k+ population\n",
    "def read_csv(path):\n",
    "    #print(\"Reading\", path)\n",
    "    return pd.read_csv(path, dtype=dtypes)\n",
    "\n",
    "\n",
    "args = list()\n",
    "for csv in os.listdir(output_path):\n",
    "    args.append(output_path+csv)\n",
    "\n",
    "print(\"Files prepared:\", len(args), \"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(os.cpu_count()) as pool:\n",
    "    results = pool.map(read_csv , args)\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(\"Files loaded.\")\n",
    "events = pd.concat(results)\n",
    "events.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.info()\n",
    "del results\n",
    "#events.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pool\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.legMode.value_counts()\n",
    "#events.facility.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(events.person == \"8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = events.loc[np.where(events.person == 1.0)]\n",
    "#display(person.head(10))\n",
    "#person.iloc[np.where(person.legMode == \"walk\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading people to separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "people = [\n",
    "        {id: 1,\n",
    "        events: [\n",
    "                {event_id :,\n",
    "                 time: \n",
    "                 type:\n",
    "                 link:\n",
    "                 vehicle_id:\n",
    "                 delay:\n",
    "                 coords: [x,y]\n",
    "                 destination:  Act)\n",
    "                 }\n",
    "        ]}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def load_events(row):\n",
    "    event = {}\n",
    "    event[\"event_id\"] = row[0]\n",
    "    event[\"time\"] = row[\"time\"]\n",
    "    event[\"type\"] = row[\"type\"]\n",
    "    event[\"link\"] = row[\"link\"]\n",
    "    event[\"vehicle_id\"] = row[\"vehicle\"]\n",
    "    event[\"delay\"] = row[\"delay\"]\n",
    "    event[\"actType\"] = row[\"actType\"]\n",
    "    event[\"legMode\"] = row[\"legMode\"]\n",
    "    event[\"coords_x\"] = row[\"x\"]\n",
    "    event[\"coords_y\"] = row[\"y\"]\n",
    "    return event\n",
    "\n",
    "def save_agents(persons, json_file, chunk_size=-1):\n",
    "    people = pd.DataFrame()\n",
    "    counter = 0\n",
    "    chunk_i = 0\n",
    "    for person in persons:\n",
    "        agent = pd.DataFrame(person[1])\n",
    "        agent_id = person[0]\n",
    "        agent = agent.sort_values(\"time\")\n",
    "        #print(\"Person Id:\", agent_id)\n",
    "        events = []\n",
    "        for id, row in agent.iterrows():\n",
    "            events.append(load_events(row))\n",
    "\n",
    "        new_vehicle = pd.DataFrame(columns=['id','events'])\n",
    "        new_vehicle.loc[0,'id'] = agent_id\n",
    "        new_vehicle.loc[0,'events']  =  events\n",
    "        people = people.append(new_vehicle)\n",
    "\n",
    "        if(chunk_size != -1 and counter > 0 and counter % chunk_size == 0):\n",
    "            if not os.path.exists(json_file+\"/agent\"):\n",
    "                os.makedirs(json_file+\"/agent\")\n",
    "            \n",
    "            people.reset_index(drop=True, inplace=True)\n",
    "            people.to_json(json_file+\"/agent/\"+str(chunk_i)+\".json\", lines=True, orient='records') \n",
    "            people = pd.DataFrame()\n",
    "            chunk_i+=1\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "    people.reset_index(drop=True, inplace=True)\n",
    "    if(chunk_size == -1):\n",
    "        people.to_json(json_file+\"/agent.json\", lines=True, orient='records')\n",
    "    else:  \n",
    "        if not os.path.exists(json_file+\"/agent\"):\n",
    "            os.makedirs(json_file+\"/agent\")\n",
    "        people.to_json(json_file+\"/agent/\"+str(chunk_i)+\".json\", lines=True, orient='records') \n",
    "\n",
    "        \n",
    "    print(\"People save to:\", json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq solution\n",
    "#agents = pd.DataFrame()\n",
    "#agents =  events[pd.to_numeric(events['person'], errors='coerce').notnull()] # removes drivers\n",
    "#agents.head()\n",
    "#agents.vehicle.unique()\n",
    "# #save_agents(agents.groupby(\"person\"), json_file = \"./../output/events\", chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(args):\n",
    "    persons, json_file, chunk_i = args\n",
    "    people = pd.DataFrame()\n",
    "    for person in persons:\n",
    "        agent_id = person.person.unique()[0]\n",
    "        agent = person.sort_values(\"time\")\n",
    "        #print(\"Person Id:\", agent_id)\n",
    "        events = []\n",
    "        for id, row in agent.iterrows():\n",
    "            events.append(load_events(row))\n",
    "\n",
    "        new_person = pd.DataFrame(columns=['id','events'])\n",
    "        new_person.loc[0,'id'] = agent_id\n",
    "        new_person.loc[0,'events']  =  events\n",
    "        people = people.append(new_person)\n",
    "        del person\n",
    "\n",
    "    if not os.path.exists(json_file+\"/agent\"):\n",
    "        os.makedirs(json_file+\"/agent\")\n",
    "            \n",
    "    people.reset_index(drop=True, inplace=True)\n",
    "    people.to_json(json_file+\"/agent/\"+str(chunk_i)+\".json\", lines=True, orient='records')\n",
    "    del people\n",
    "    gc.collect()\n",
    "    return\n",
    "\n",
    "\n",
    "def save_agents_parallel(persons, json_file, chunk_size=500):\n",
    "    chunks_count = (len(persons)/chunk_size)\n",
    "    if(len(persons)%chunk_size > 0):\n",
    "        chunks_count += 1\n",
    "\n",
    "    #split persons into chunks\n",
    "    print(\"Chunks:\", chunks_count)\n",
    "    args = list()\n",
    "    chunk = []\n",
    "    chunk_i  = 0\n",
    "    for e,p in enumerate(persons):\n",
    "        if(len(chunk) > 0 and e % chunk_size == 0):\n",
    "            args.append([chunk, json_file, chunk_i])\n",
    "            chunk = []\n",
    "            chunk_i +=1\n",
    "        chunk.append(p)\n",
    "\n",
    "    if len(chunk) > 0:\n",
    "        args.append([chunk, json_file, chunk_i])\n",
    "\n",
    "    print(\"Args:\", len(args))\n",
    "    with Pool(os.cpu_count()//2) as pool:\n",
    "        pool.map(process_chunk, args)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(\"Agents processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = pd.DataFrame()\n",
    "agents =  events[pd.to_numeric(events['person'], errors='coerce').notnull()] # removes drivers\n",
    "dfs = [x for _, x in agents.groupby(\"person\")]\n",
    "del agents\n",
    "gc.collect()\n",
    "save_agents_parallel(dfs, json_file = \"./../output/events\", chunk_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading vehicle events to separate files\n",
    "\n",
    "- cars\n",
    "- subway\n",
    "- buses\n",
    "- trams\n",
    "- trains\n",
    "- ferry\n",
    "- funicular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, vehicle_type):\n",
    "    event = {}\n",
    "    event[\"event_id\"] = row[0]\n",
    "    event[\"time\"] = row[\"time\"]\n",
    "    event[\"type\"] = row[\"type\"]\n",
    "    event[\"link\"] = row[\"link\"]\n",
    "    event[\"person_id\"] = row[\"person\"]\n",
    "    event[\"delay\"] = row[\"delay\"]\n",
    "    event[\"facility\"] = row['facility']\n",
    "            #if facility, parse out link\n",
    "            #print(type(row['facility']))\n",
    "    if isinstance(row['facility'],str): #and not(np.isnan(row['facility'])):\n",
    "                #print(\"filling link\", row['facility'],row['facility'].split(\":\")[-1])\n",
    "        event['link'] = row['facility'].split(\":\")[-1]\n",
    "                #return\n",
    "    event[\"networkMode\"] = row['networkMode']\n",
    "    event[\"relativePosition\"] = row['relativePosition']\n",
    "    event[\"actType\"] = row[\"actType\"]\n",
    "    event[\"legMode\"] = row[\"legMode\"]\n",
    "    event[\"coords_x\"] = row[\"x\"]\n",
    "    event[\"coords_y\"] = row[\"y\"]\n",
    "\n",
    "    if(vehicle_type != \"car\"):\n",
    "        if(event[\"type\"] == \"TransitDriverStarts\"):\n",
    "                    #print(\"Driver starts\")\n",
    "            event[\"transitLine\"] = row['transitLineId']\n",
    "            event[\"transitRoute\"] = row['transitRouteId'] ## add to output\n",
    "        event[\"departure\"] = row['departureId']\n",
    "        event[\"atStop\"] = row[\"atStop\"]\n",
    "        event[\"destinationStop\"] = row[\"destinationStop\"]\n",
    "    return event\n",
    "\n",
    "\n",
    "\n",
    "def save_vehicle(vehicle_events, json_file, vehicle_type = \"\", chunk_size=-1):\n",
    "    print(\"Saving vehicle\", vehicle_type)\n",
    "    vehicles = pd.DataFrame()\n",
    "    counter = 0\n",
    "    chunk_i = 0\n",
    "    ids_in_chunks = {}\n",
    "    for agent in vehicle_events:\n",
    "        vehicle = pd.DataFrame(agent[1])\n",
    "        vehicle = vehicle.sort_values(\"time\")\n",
    "        events = []\n",
    "        if(vehicle_type == \"car\"):\n",
    "            vehicle_id = int(vehicle.vehicle.unique()[0])\n",
    "        else:\n",
    "            vehicle_id = vehicle.vehicle.unique()[0]\n",
    "\n",
    "        ids_in_chunks[vehicle_id] = chunk_i\n",
    "\n",
    "        #parse events\n",
    "        for id, row in vehicle.iterrows():\n",
    "            event = process_row(row, vehicle_type)\n",
    "            events.append(event)\n",
    "            \n",
    "        new_vehicle = pd.DataFrame(columns=['id','events'])\n",
    "        new_vehicle.loc[0,'id'] = vehicle_id\n",
    "        new_vehicle.loc[0,'events']  =  events\n",
    "        vehicles = vehicles.append(new_vehicle)\n",
    "        vehicles.reset_index(drop=True, inplace=True)\n",
    "        if(chunk_size != -1 and counter > 0 and counter % chunk_size == 0):\n",
    "            if not os.path.exists(json_file+\"/\"+vehicle_type):\n",
    "                os.makedirs(json_file+\"/\"+vehicle_type)\n",
    "            vehicles.to_json(json_file+\"/\"+vehicle_type+\"/\"+str(chunk_i)+\".json\", lines=True, orient='records') \n",
    "            vehicles = pd.DataFrame()\n",
    "            chunk_i+=1\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    vehicles.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if(chunk_size == -1):\n",
    "        vehicles.to_json(json_file+\"/\"+vehicle_type+\".json\", lines=True, orient='records')  \n",
    "    else:\n",
    "        if not os.path.exists(json_file+\"/\"+vehicle_type):\n",
    "            os.makedirs(json_file+\"/\"+vehicle_type)\n",
    "        vehicles.to_json(json_file+\"/\"+vehicle_type+\"/\"+str(chunk_i)+\".json\", lines=True, orient='records') \n",
    "        \n",
    "    with open(json_file+\"/\"+vehicle_type+'_map.json', 'w') as f:\n",
    "        json.dump(ids_in_chunks,f)\n",
    "    del vehicles \n",
    "    gc.collect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_vehicle_events(vehicle_type, json_path=\"./../output/events\"):\n",
    "    print(\"Started filtering:\",vehicle_type, \"at\", datetime.now())\n",
    "    vehicles = pd.DataFrame()\n",
    "    if vehicle_type == 'car':\n",
    "        vehicles = events[pd.to_numeric(events['vehicle'], errors='coerce').notnull()]\n",
    "    else:\n",
    "        vehicles = events.loc[events['vehicle'].str.contains(vehicle_type, case=False)]\n",
    "        driver_events = events[events['vehicleId'].notnull() & events['vehicleId'].str.contains(vehicle_type, case=False)]\n",
    "        driver_events['vehicle'] = driver_events['vehicleId']\n",
    "        vehicles = vehicles.append(driver_events)\n",
    "        \n",
    "    save_vehicle(vehicles.groupby(\"vehicle\"), json_file = json_path, vehicle_type=vehicle_type, chunk_size=500)\n",
    "    print(\"Saved vehicle type:\",vehicle_type, \"to\", json_path, \"at\", datetime.now())\n",
    "    del vehicles\n",
    "    gc.collect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential solution\n",
    "#for veh_type in [\"subway\"]:#['bus',\"car\",\"funicular\"]: #tram, subway\n",
    "#        \n",
    "#        filter_vehicle_events(veh_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_types = [\"bus\"] #\"car\",\"funicular\",\"subway\", ,\"bus\"\n",
    "events.vehicle = events.vehicle.astype(\"string\")\n",
    "with Pool(min(os.cpu_count(), len(vehicle_types))) as pool: #todo vehicle chunks, issue with RAM\n",
    "    pool.map(filter_vehicle_events, vehicle_types)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4d000ebc1070b3c4f02c761be1e96128dc18de4056499f92a4920e8dfd6dfe9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
