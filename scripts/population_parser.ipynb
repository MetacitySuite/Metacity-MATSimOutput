{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import warnings\n",
    "import gc\n",
    "from memory_profiler import profile\n",
    "from multiprocessing import Pool\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "output_path = \"./../output/population/\"\n",
    "agents_path = \"./../output/agents/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"Unnamed: 0\" : np.float64,\n",
    "    \"time\": np.float64,\n",
    "    \"type\": str,\n",
    "    \"driverId\": str,\n",
    "    \"vehicleId\": str,\n",
    "    \"transitLineId\": str,\n",
    "    \"transitRouteId\": str,\n",
    "    \"departureId\": str,\n",
    "    \"person\": str,\n",
    "    \"link\": str,\n",
    "    \"legMode\": 'category', #category\n",
    "    \"vehicle\": str,\n",
    "    \"networkMode\": str, #category\n",
    "    \"relativePosition\": np.float64,\n",
    "    \"facility\": str,\n",
    "    \"delay\": np.float64,\n",
    "    \"x\": np.float64,\n",
    "    \"y\": np.float64,\n",
    "    \"actType\": str,\n",
    "    \"computationalRoutingMode\": str,\n",
    "    \"distance\" : np.float64,\n",
    "    \"mode\": str,\n",
    "    \"agent\": str,\n",
    "    \"atStop\": str\n",
    "}\n",
    "\n",
    "vehicle_types = [\"bus\",\"car\",\"funicular\",\"subway\", \"tram\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files prepared: 3 files\n"
     ]
    }
   ],
   "source": [
    "def read_csv(path):\n",
    "    return pd.read_csv(path, dtype=dtypes)\n",
    "\n",
    "def clear_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    else:\n",
    "        shutil.rmtree(directory)\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "args = list()\n",
    "\n",
    "for csv in os.listdir(output_path):\n",
    "    args.append(output_path+csv)\n",
    "\n",
    "print(\"Files prepared:\", len(args), \"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_agent_events(row):\n",
    "    event = {}\n",
    "    event[\"event_id\"] = row[0]\n",
    "    event[\"time\"] = row[\"time\"]\n",
    "    event[\"type\"] = row[\"type\"]\n",
    "    event[\"link\"] = row[\"link\"]\n",
    "    event[\"vehicle_id\"] = row[\"vehicle\"]\n",
    "    event[\"delay\"] = row[\"delay\"]\n",
    "    event[\"actType\"] = row[\"actType\"]\n",
    "    event[\"legMode\"] = row[\"legMode\"]\n",
    "    event[\"coords_x\"] = row[\"x\"]\n",
    "    event[\"coords_y\"] = row[\"y\"]\n",
    "    return event\n",
    "\n",
    "def load_vehicle_events(row, vehicle_type):\n",
    "    event = {}\n",
    "    event[\"event_id\"] = row[0]\n",
    "    event[\"time\"] = row[\"time\"]\n",
    "    event[\"type\"] = row[\"type\"]\n",
    "    event[\"link\"] = row[\"link\"]\n",
    "    event[\"person_id\"] = row[\"person\"]\n",
    "    event[\"delay\"] = row[\"delay\"]\n",
    "    event[\"facility\"] = row['facility']\n",
    "\n",
    "    if isinstance(row['facility'],str):\n",
    "        event['link'] = row['facility'].split(\":\")[-1]\n",
    "    \n",
    "    event[\"networkMode\"] = row['networkMode']\n",
    "    event[\"relativePosition\"] = row['relativePosition']\n",
    "    event[\"actType\"] = row[\"actType\"]\n",
    "    event[\"legMode\"] = row[\"legMode\"]\n",
    "    event[\"coords_x\"] = row[\"x\"]\n",
    "    event[\"coords_y\"] = row[\"y\"]\n",
    "\n",
    "    if(vehicle_type != \"car\"):\n",
    "        if(event[\"type\"] == \"TransitDriverStarts\"):\n",
    "            event[\"transitLine\"] = row['transitLineId']\n",
    "            event[\"transitRoute\"] = row['transitRouteId'] ## add to output\n",
    "        event[\"departure\"] = row['departureId']\n",
    "        event[\"atStop\"] = row[\"atStop\"]\n",
    "        event[\"destinationStop\"] = row[\"destinationStop\"]\n",
    "    return event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunk(path, file, chunk):\n",
    "    #check if exists\n",
    "    #print(\"saving chunk\", file)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    #open load and append\n",
    "    with open(path+file, 'w') as f:\n",
    "        if(os.path.getsize(path+file) == 0):\n",
    "            json.dump(chunk,f)\n",
    "        else:\n",
    "            saved = json.load(f)\n",
    "            saved[\"events\"].extend(chunk[\"events\"])\n",
    "            json.dump(saved,f)\n",
    "    return\n",
    "\n",
    "def process_agent(person):\n",
    "    agent_id = person.person.unique()[0]\n",
    "    agent = person.sort_values(\"time\")\n",
    "    #print(\"Person Id:\", agent_id)\n",
    "    events = []\n",
    "    chunk = {\n",
    "        \"id\" : agent_id,\n",
    "        \"events\" : []\n",
    "    }\n",
    "    for i, row in agent.iterrows():\n",
    "        events.append(load_agent_events(row))\n",
    "\n",
    "    chunk[\"events\"] = events\n",
    "    save_chunk(agents_path+\"/agent\",\"/\"+str(agent_id)+\".json\", chunk)\n",
    "    return\n",
    "\n",
    "def process_vehicle(args):\n",
    "    vehicle_df, vehicle_type = args\n",
    "    vehicle_id = vehicle_df.vehicle.unique()[0] #(?)\n",
    "    vehicle = vehicle_df.sort_values(\"time\")\n",
    "    events = []\n",
    "    \n",
    "    if(vehicle_type == \"car\"):\n",
    "        vehicle_id = int(vehicle.vehicle.unique()[0])\n",
    "    else:\n",
    "        vehicle_id = vehicle.vehicle.unique()[0]\n",
    "\n",
    "    chunk = {\n",
    "        \"id\" : vehicle_id,\n",
    "        \"events\" : []\n",
    "    }\n",
    "\n",
    "    for i, row in vehicle.iterrows():\n",
    "        events.append(load_vehicle_events(row, vehicle_type))\n",
    "\n",
    "    chunk[\"events\"] = events\n",
    "    save_chunk(agents_path+\"/\"+vehicle_type,\"/\"+str(vehicle_id)+\".json\", chunk)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def save_agents_parallel(persons, cpus):\n",
    "    print(\"Number of agents in loaded chunk:\", len(persons))\n",
    "    print(\"processing:\")\n",
    "    with Pool(cpus) as pool:\n",
    "        pool.map(process_agent, persons)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return\n",
    "\n",
    "\n",
    "def save_vehicles_parallel(args, cpus):\n",
    "    print(\"Number of vehicles in loaded chunk:\", len(args))\n",
    "\n",
    "    print(\"processing:\")\n",
    "    with Pool(cpus) as pool:\n",
    "        pool.map(process_vehicle, args)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return\n",
    "\n",
    "\n",
    "def load_agents_from_population(path):\n",
    "    print(\"Loading file:\", path)\n",
    "    events = pd.read_csv(path, dtype=dtypes) #.fillna(np.nan)\n",
    "    print(\"Parsing events:\")\n",
    "    agent_loads = []\n",
    "\n",
    "    print(\"\\t Grouping agents:\")\n",
    "    agents = pd.DataFrame()\n",
    "    # removes drivers\n",
    "    agents =  events[pd.to_numeric(events['person'], errors='coerce').notnull()] \n",
    "    dfs = [x for _, x in agents.groupby(\"person\")] #each person in own dataframe\n",
    "    del agents\n",
    "    gc.collect()\n",
    "    print(\"\\t agents # \",len(dfs))\n",
    "    agent_loads.append(len(dfs))\n",
    "\n",
    "    events.vehicle = events.vehicle.astype(\"string\")\n",
    "    vehicle_dfs = []\n",
    "    vehicle_dfs_types = []\n",
    "    args = []\n",
    "\n",
    "    for veh_type in vehicle_types:\n",
    "        print(\"\\t Grouping\",veh_type,\":\")\n",
    "        \n",
    "        vehicles = pd.DataFrame()\n",
    "        if veh_type == 'car':\n",
    "            vehicles = events[pd.to_numeric(events['vehicle'], errors='coerce').notnull()]\n",
    "        else:\n",
    "            vehicles = events.loc[events['vehicle'].str.contains(veh_type, case=False)]\n",
    "            driver_events = events[events['vehicleId'].notnull() & events['vehicleId'].str.contains(veh_type, case=False)]\n",
    "            driver_events['vehicle'] = driver_events['vehicleId']\n",
    "            vehicles = vehicles.append(driver_events)\n",
    "            \n",
    "        vehs = [x for _, x in vehicles.groupby(\"vehicle\")]\n",
    "        vehicle_dfs.extend(vehs)\n",
    "        vehicle_dfs_types.extend([veh_type]*len(vehs))\n",
    "        print(\"\\t\",veh_type,\"# \",len(vehs))\n",
    "        agent_loads.append(len(vehs))\n",
    "    \n",
    "    args = [ [df,t] for df,t in zip(vehicle_dfs, vehicle_dfs_types)]\n",
    "    del vehicle_dfs\n",
    "    del vehicle_dfs_types\n",
    "\n",
    "    total_agents = sum(agent_loads)\n",
    "    cpu_available = os.cpu_count()\n",
    "\n",
    "    del events\n",
    "    gc.collect()\n",
    "    save_vehicles_parallel(args, cpu_available)\n",
    "    save_agents_parallel(dfs, cpu_available)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: ./../output/population/0.csv\n",
      "Parsing events:\n",
      "\t Grouping agents:\n",
      "\t agents #  10000\n",
      "\t Grouping bus :\n",
      "\t bus #  9717\n",
      "\t Grouping car :\n",
      "\t car #  5160\n",
      "\t Grouping funicular :\n",
      "\t funicular #  48\n",
      "\t Grouping subway :\n",
      "\t subway #  925\n",
      "\t Grouping tram :\n",
      "\t tram #  3232\n",
      "Number of vehicles in loaded chunk: 19082\n",
      "processing:\n",
      "Number of agents in loaded chunk: 10000\n",
      "processing:\n",
      "Loading file: ./../output/population/1.csv\n",
      "Parsing events:\n",
      "\t Grouping agents:\n",
      "\t agents #  8682\n",
      "\t Grouping bus :\n",
      "\t bus #  11447\n",
      "\t Grouping car :\n",
      "\t car #  4560\n",
      "\t Grouping funicular :\n",
      "\t funicular #  74\n",
      "\t Grouping subway :\n",
      "\t subway #  874\n",
      "\t Grouping tram :\n",
      "\t tram #  3389\n",
      "Number of vehicles in loaded chunk: 20344\n",
      "processing:\n",
      "Number of agents in loaded chunk: 8682\n",
      "processing:\n",
      "Loading file: ./../output/population/2.csv\n",
      "Parsing events:\n",
      "\t Grouping agents:\n",
      "\t agents #  3\n",
      "\t Grouping bus :\n",
      "\t bus #  3008\n",
      "\t Grouping car :\n",
      "\t car #  0\n",
      "\t Grouping funicular :\n",
      "\t funicular #  0\n",
      "\t Grouping subway :\n",
      "\t subway #  6\n",
      "\t Grouping tram :\n",
      "\t tram #  372\n",
      "Number of vehicles in loaded chunk: 3386\n",
      "processing:\n",
      "Number of agents in loaded chunk: 3\n",
      "processing:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clear_directory(agents_path+\"/agent\")\n",
    "for veh_type in vehicle_types:\n",
    "    clear_directory(agents_path+\"/\"+veh_type)\n",
    "\n",
    "for csv in args[:]:\n",
    "    load_agents_from_population(csv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'events' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7669/177820107.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m#person event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'person'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'person'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_agent_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'events' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i,event in tqdm(events.iterrows()):\n",
    "        #person event\n",
    "        if event['person'] == event['person'] and event.person.isnumeric():\n",
    "            try:\n",
    "                loaded = load_agent_events(event)\n",
    "                agent_id = event[\"person\"]\n",
    "\n",
    "                if(agent_id in agents.keys()):\n",
    "                    agents[agent_id][\"events\"].append(loaded)\n",
    "                    if len(agents[agent_id][\"events\"]) >= 50000:\n",
    "                        #append to file\n",
    "                        save_chunk(agents_path+\"/agent\",\"/\"+str(agent_id)+\".json\", agents[agent_id])\n",
    "                        agents[agent_id][\"events\"] = []\n",
    "    \n",
    "                else:\n",
    "                    agents[agent_id] = { \"id\": agent_id, \"events\":[] }\n",
    "            except KeyError:\n",
    "                print(event, path, event.type)\n",
    "\n",
    "        #vehicle event\n",
    "        if event.vehicle == event.vehicle: # or (event.person == event.person and not event.person.isnumeric()):\n",
    "            #print(event)\n",
    "            vehicle_type = \"\"\n",
    "            if event.vehicle == event.vehicle  and (event.vehicle.isnumeric()):\n",
    "                vehicle_type = \"car\"\n",
    "            else:\n",
    "                vehicle_type = event[\"vehicle\"].split('_')[-1]\n",
    "\n",
    "\n",
    "            vehicle_id = event[\"vehicle\"]\n",
    "            try:\n",
    "                loaded = load_vehicle_events(event, vehicle_type)\n",
    "                if(not vehicle_type in vehicles.keys()):\n",
    "                    vehicles[vehicle_type] = {}\n",
    "\n",
    "                if(vehicle_id in vehicles[vehicle_type].keys()):\n",
    "                    vehicles[vehicle_type][vehicle_id][\"events\"].append(loaded)\n",
    "                    if len(vehicles[vehicle_type][vehicle_id][\"events\"]) >= 50000:\n",
    "                        #append to file\n",
    "                        save_chunk(agents_path+\"/\"+vehicle_type,\"/\"+str(vehicle_id)+\".json\", vehicles[vehicle_type][vehicle_id])\n",
    "                        vehicles[vehicle_type][vehicle_id][\"events\"] = []\n",
    "\n",
    "                else:\n",
    "                    vehicles[vehicle_type][vehicle_id] = { \"id\": vehicle_id, \"events\":[] }\n",
    "                    \n",
    "            except KeyError:\n",
    "                print(event, path)\n",
    "                #return\n",
    "\n",
    "    del events\n",
    "    gc.collect()\n",
    "    \n",
    "    for agent_id in agents.keys():\n",
    "        save_chunk(agents_path+\"/agent\",\"/\"+str(agent_id)+\".json\", agents[agent_id])\n",
    "\n",
    "    for vehicle_type in vehicles.keys():\n",
    "        for vehicle_id in vehicles[vehicle_type].keys():\n",
    "            save_chunk(agents_path+\"/\"+vehicle_type,\"/\"+str(vehicle_id)+\".json\", vehicles[vehicle_type][vehicle_id])\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30f0103485fa261618a8c595a0abf0368cef3d01076c0a3e06f386f93a4f7fa5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
