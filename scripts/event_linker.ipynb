{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event linker\n",
    "\n",
    "Where we link people and vehicles. Now moved to exporter.py and agent.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network as net\n",
    "n = net.network()\n",
    "n.set_path('../../pop10k-eh4-qsim2-100it/output_network.xml.gz')\n",
    "n.status()\n",
    "\n",
    "n.load_nodes()\n",
    "n.load_links()\n",
    "n.join_network()\n",
    "network = n.return_network()\n",
    "\n",
    "#display(net.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(network.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_json(\"./../output/events/agents.json\")\n",
    "\n",
    "people.sort_values(\"id\", kind=\"stable\", inplace=True)\n",
    "people.set_index(\"id\", inplace=True)\n",
    "display(people.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vehicles(vehicle_types, path):\n",
    "    vehicle_dict = {}\n",
    "    for veh_type in vehicle_types:\n",
    "        df = pd.DataFrame()\n",
    "        df = pd.read_json(path+veh_type+\".json\")\n",
    "        df.sort_values(\"id\", kind=\"stable\", inplace=True)\n",
    "        df.set_index(\"id\", inplace=True)\n",
    "        #link coords\n",
    "        vehicle_dict[str(veh_type)] = df.copy()\n",
    "        print(\"Vehicle\", veh_type, len(df.index.unique()))\n",
    "\n",
    "    return vehicle_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transport = load_vehicles([\"car\",\"subway\",\"bus\",\"tram\",\"ferry\",\"rail\",\"funicular\"],\"./output/events/\")\n",
    "transport = load_vehicles([\"car\",\"subway\",\"bus\",\"tram\",\"funicular\"],\"./../output/events/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking people and vehicles\n",
    "- link cars when entering\n",
    "- link mhd when waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_vehicles(df, person_id, vehicle_ids, verbal=False):\n",
    "    events = pd.DataFrame()\n",
    "    for v_id in vehicle_ids:\n",
    "        if v_id is not None:\n",
    "            veh_events = pd.DataFrame()\n",
    "            if(verbal):\n",
    "                print(\"Vehicle id:\",v_id)\n",
    "\n",
    "            if(str(v_id).isnumeric()):\n",
    "                if(verbal):\n",
    "                    print(\"\\tVehicle type:\", \"car\")\n",
    "                car_row = transport['car'].loc[int(v_id)]\n",
    "                car = pd.DataFrame.from_dict(car_row[\"events\"])\n",
    "\n",
    "                starts = df.iloc[np.where(df.vehicle_id == v_id)].loc[np.where(df.type == \"PersonEntersVehicle\")].time.to_list()\n",
    "                ends = df.iloc[np.where(df.vehicle_id == v_id)].loc[np.where(df.type == \"PersonLeavesVehicle\")].time.to_list()\n",
    "\n",
    "                car[\"vehicle_id\"] = v_id\n",
    "                for start,dest in zip(starts,ends):\n",
    "                    if(verbal):\n",
    "                        print(start, dest)\n",
    "                        #display(car.iloc[np.where((car[\"time\"] >= start) & (car[\"time\"]<= dest))])\n",
    "                    veh_events = veh_events.append(car.iloc[np.where((car[\"time\"] >= start) & (car[\"time\"]<= dest))])\n",
    "            elif  v_id.split('_')[-1] in transport.keys():\n",
    "                veh_type = v_id.split('_')[-1]\n",
    "                if(verbal):\n",
    "                    print(\"\\tVehicle type:\", veh_type)\n",
    "                veh_row = transport[veh_type].loc[v_id]\n",
    "                vehicle = pd.DataFrame.from_dict(veh_row[\"events\"])\n",
    "                vehicle[\"vehicle_id\"] = v_id\n",
    "\n",
    "                #tohle je spatne # tak uz dobry\n",
    "                a = df.iloc[np.where(df.vehicle_id == v_id)] #pick start and end points of vehicle interaction(s)\n",
    "                starts = a.iloc[np.where(a.type == \"PersonEntersVehicle\")].time.to_list()\n",
    "                ends = a.iloc[np.where(a.type == \"PersonLeavesVehicle\")].time.to_list()\n",
    "                for start,dest in zip(starts,ends):\n",
    "                    if(verbal):\n",
    "                        print(start, dest)\n",
    "                        display(vehicle.iloc[np.where((vehicle[\"time\"] >= start) & (vehicle[\"time\"]<= dest))])\n",
    "                    veh_events = veh_events.append(vehicle.iloc[np.where((vehicle[\"time\"] >= start) & (vehicle[\"time\"]<= dest))])\n",
    "                \n",
    "            #drop events\n",
    "            if('type' in veh_events.columns):\n",
    "                drop_idx = veh_events[\n",
    "                            ((veh_events['type'] == \"PersonEntersVehicle\") & (veh_events['person_id'] != str(person_id))) | #\n",
    "                            ((veh_events['type'] == \"PersonLeavesVehicle\") & (veh_events['person_id'] != str(person_id))) | #\n",
    "                            #(veh_events['type'] == \"departure\") | \n",
    "                            #(veh_events['type'] == \"arrival\") | \n",
    "                            (veh_events['type'] == \"vehicle leaves traffic\") | \n",
    "                            (veh_events['type'] == \"vehicle enters traffic\") |\n",
    "                            (veh_events['type'] == \"left link\")\n",
    "                            ].index      \n",
    "                veh_events.drop(drop_idx, inplace=True)\n",
    "            #display(veh_events.type.unique())  \n",
    "            #print(\"person_id\",person_id, veh_events.person_id.unique())\n",
    "            #display(veh_events)  \n",
    "            events = events.append(veh_events)\n",
    "    df = df.append(events, ignore_index=True)\n",
    "    df = df.sort_values([\"time\"], kind=\"stable\") #, \"type\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500\n",
    "chunk = pd.DataFrame()\n",
    "\n",
    "last_id = 0\n",
    "last_chunk = 0\n",
    "chunk_no = last_chunk\n",
    "\n",
    "for id, row in people.iterrows():\n",
    "    df = pd.DataFrame.from_dict(row[\"events\"])\n",
    "    vehicle_ids = [ x for x in list(df.vehicle_id.unique())] #veh ids\n",
    "    #print(\"Vehicle ids:\", vehicle_ids)\n",
    "    df = append_vehicles(df, id, vehicle_ids, verbal=False)\n",
    "    m = df.reset_index()\n",
    "    m.drop(columns=[\"index\"], inplace=True)\n",
    "    drop_idx = m[\n",
    "        #(m['type'] == \"departure\") | \n",
    "        #(m['type'] == \"arrival\") | \n",
    "        (m['type'] == \"vehicle leaves traffic\") | \n",
    "        (m['type'] == \"vehicle enters traffic\") |\n",
    "        (m['type'] == \"left link\")\n",
    "        ].index\n",
    "    m.drop(drop_idx, inplace=True)\n",
    "\n",
    "    #merge with links\n",
    "    ml = m.join(network.set_index(\"link\"), on='link').fillna(value=np.nan)\n",
    "    ml.drop([\"from\",\"to\",\"length\",\"event_id\",\"permlanes\",'capacity','link_modes'], axis=1, inplace=True)\n",
    "    #ml[\"duration\"] = ml.time.diff().replace(np.nan, 0)\n",
    "    ml[\"person_id\"] = id\n",
    "    chunk = chunk.append(ml)\n",
    "    if(id % chunk_size == 0):\n",
    "        chunk.reset_index()\n",
    "        chunk.to_csv(\"./../output/plans/\"+str(chunk_no)+\".csv\")\n",
    "        chunk_no +=1\n",
    "        chunk = pd.DataFrame()\n",
    "        #break\n",
    "    vehicle_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_ids = np.where(chunk['vehicle_id']==10.0)\n",
    "vehicle = chunk.iloc[car_ids]\n",
    "sharers = chunk.loc[chunk['person_id'].isin(vehicle.person_id.unique())]\n",
    "sharers.actType.unique()\n",
    "print(\"Car is used by: \",vehicle.person_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = sharers.iloc[np.where((sharers.actType == \"home\"))]\n",
    "display(homes[\"coords_from\"])\n",
    "\n",
    "jobs = sharers.iloc[np.where((sharers.actType == \"work\"))]\n",
    "display(jobs[\"coords_from\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4d000ebc1070b3c4f02c761be1e96128dc18de4056499f92a4920e8dfd6dfe9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
